# finds and enqueues links on a page
step1: com.intelliseek.spider.html.AnalyzeLinks

# write XHTML pages to output
step2: com.endeca.crawler.output.EndecaOutputStep

# selectively filters out URLs
step3: com.endeca.crawler.UrlFilterStep

# writes all the URLs and their response codes to a file
step4: com.intelliseek.spider.ListURL
step4.fileName = all-urls.lst

# write stats for each Spider when it finishes
step5: com.intelliseek.spider.LogStats
step5.fileName = spider.done

# Set these to give administrators your contact information
#core.http.userAgentURL = http://www.mycompany.com/crawler
#core.http.fromEmail = help@mycompany.com
core.http.userAgent = Endeca Web Crawler

# spider properties
core.spider.validExtensions=.html .pdf .doc .xls .rtf .txt .asp .jsp .shtml .ppt .xlw .mdb .dbf .ps .ps.gz .cfm .php
core.spider.dataHandlers=com.intelliseek.spider.html.DocumentDataHandler,com.intelliseek.spider.DataHandler
core.spider.requestDelayNoPipeline = 200
core.spider.requestDelay = 200	
core.spider.handleThrottle = 40
core.spider.processThrottle = 20
core.spider.siteTimeLimit = 0
core.spider.offsiteMode = SAME_HOST
core.spider.sharedRequestQueue = true
core.spider.spidersPerSeed = 2
core.spider.fetcherThreads = 5 	
core.spider.handlerThreads = 2	
core.spider.processorThreads = 5	


# http properties
core.http.autoFollowRedirects = false
core.http.prependWWW = false

# logging properties
loglevel.com.intelliseek.spider = 1
core.spider.logRoot = ./crawl

